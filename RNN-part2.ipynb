{"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"sourceId":320111,"sourceType":"datasetVersion","datasetId":134715}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# data manipulation\nimport pandas as pd\nimport numpy as np\n\n# data visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# text processing\nimport re\nimport nltk\nfrom nltk.tokenize import word_tokenize, sent_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem.wordnet import WordNetLemmatizer\nnltk.download('stopwords')\nnltk.download('wordnet')\nstopwords = set(stopwords.words('english'))\n\n# pytorch\nimport torch\nfrom torch import nn\nfrom torch.optim import Adam\nfrom torch.utils.data import TensorDataset, DataLoader\n\n# sklearn\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n# utils\nimport os\nfrom tqdm import tqdm\ntqdm.pandas()\nfrom collections import Counter\n\n# WordNet\n!unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora/","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:15:54.604890Z","iopub.execute_input":"2024-04-25T17:15:54.605343Z","iopub.status.idle":"2024-04-25T17:16:05.495440Z","shell.execute_reply.started":"2024-04-25T17:15:54.605298Z","shell.execute_reply":"2024-04-25T17:16:05.493905Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\nArchive:  /usr/share/nltk_data/corpora/wordnet.zip\n   creating: /usr/share/nltk_data/corpora/wordnet/\n  inflating: /usr/share/nltk_data/corpora/wordnet/lexnames  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.verb  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.adv  \n  inflating: /usr/share/nltk_data/corpora/wordnet/adv.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.verb  \n  inflating: /usr/share/nltk_data/corpora/wordnet/cntlist.rev  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.adj  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.adj  \n  inflating: /usr/share/nltk_data/corpora/wordnet/LICENSE  \n  inflating: /usr/share/nltk_data/corpora/wordnet/citation.bib  \n  inflating: /usr/share/nltk_data/corpora/wordnet/noun.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/verb.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/README  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.sense  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.noun  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.adv  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.noun  \n  inflating: /usr/share/nltk_data/corpora/wordnet/adj.exc  \n","output_type":"stream"}]},{"cell_type":"code","source":"class IMDBDataset:\n    def __init__(self, dataset_path):\n        self.raw_df = pd.read_csv(dataset_path)\n\n    def do_preprocessing(self):\n        self.raw_df[\"sentiment\"] = (self.raw_df[\"sentiment\"] == \"positive\").astype(int)\n        self.raw_df = self.__clean_text(self.raw_df, \"review\")\n        self.raw_df[\"review\"] = self.raw_df[\"review\"].apply(self.__preprocess_text)\n\n        return self.raw_df\n\n    def __preprocess_text(self, text):\n        tokens = word_tokenize(text)\n        lemmatizer = WordNetLemmatizer()\n        tokens = [lemmatizer.lemmatize(t) for t in tokens]\n        tokens = [t for t in tokens if t not in stopwords]\n\n        return \" \".join(tokens)\n\n    def __clean_text(self, df, col_name):\n        df[col_name] = df[col_name].apply(self.__remove_links)\n        df[col_name] = df[col_name].apply(self.__remove_tags)\n        df[col_name] = df[col_name].apply(self.__remove_extra_whitespace)\n        df[col_name] = df[col_name].apply(self.__remove_numbers)\n        df[col_name] = df[col_name].apply(self.__remove_punctuations)\n\n        return df\n\n    def __remove_punctuations(self, text):\n        return re.sub(r\"[^\\w\\s]\", \"\", text)\n\n    def __remove_links(self, text):\n        return re.sub(r\"http\\S+|www\\S+\", \"\", text)\n\n    def __remove_tags(self, text):\n        return re.sub(r\"<[^>]+>\", \"\", text)\n\n    def __remove_extra_whitespace(self, text):\n        return re.sub(r\"\\s+\", \" \", text).strip()\n\n    def __remove_numbers(self, text):\n        return re.sub(r\"\\d+\", \"\", text)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:16:05.498883Z","iopub.execute_input":"2024-04-25T17:16:05.499798Z","iopub.status.idle":"2024-04-25T17:16:05.516062Z","shell.execute_reply.started":"2024-04-25T17:16:05.499758Z","shell.execute_reply":"2024-04-25T17:16:05.514711Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"imdb_dataset = IMDBDataset(dataset_path=\"/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\")\npreprocessed_df = imdb_dataset.do_preprocessing()\npreprocessed_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:16:05.517709Z","iopub.execute_input":"2024-04-25T17:16:05.518552Z","iopub.status.idle":"2024-04-25T17:19:25.052866Z","shell.execute_reply.started":"2024-04-25T17:16:05.518505Z","shell.execute_reply":"2024-04-25T17:19:25.051440Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                              review  sentiment\n0  One reviewer ha mentioned watching Oz episode ...          1\n1  A wonderful little production The filming tech...          1\n2  I thought wa wonderful way spend time hot summ...          1\n3  Basically family little boy Jake think zombie ...          0\n4  Petter Matteis Love Time Money visually stunni...          1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>One reviewer ha mentioned watching Oz episode ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A wonderful little production The filming tech...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I thought wa wonderful way spend time hot summ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Basically family little boy Jake think zombie ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Petter Matteis Love Time Money visually stunni...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def make_dictionary(preprocessed_df):\n    \n    all_words = ' '.join(preprocessed_df.review.values).split()\n    counter = Counter(all_words)\n    vocab = sorted(counter, key=counter.get, reverse=True)\n\n    idx_to_token = dict(enumerate(vocab, 1))\n    idx_to_token[0] = \"<SEP>\"\n    \n    token_to_idx = {token: idx for idx, token in idx_to_token.items()}\n    \n    return idx_to_token, token_to_idx\n\ndef pad_sequence(sequence, seq_length):\n    if len(sequence) >= seq_length:\n        return sequence[:seq_length]\n    else:\n        padded_sequence = sequence + [0] * (seq_length - len(sequence))\n        return padded_sequence","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:59:27.402102Z","iopub.execute_input":"2024-04-25T17:59:27.403697Z","iopub.status.idle":"2024-04-25T17:59:27.413766Z","shell.execute_reply.started":"2024-04-25T17:59:27.403647Z","shell.execute_reply":"2024-04-25T17:59:27.411820Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"idx_to_token, token_to_idx = make_dictionary(preprocessed_df)\npreprocessed_df[\"tokens\"] = preprocessed_df[\"review\"].apply(lambda x: [token_to_idx[token] for token in x.split()])\n\n# display(preprocessed_df.head())\n# lens = [len(tokens) for tokens in preprocessed_df[\"tokens\"]]\n# print(lens[:200])","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:59:29.443190Z","iopub.execute_input":"2024-04-25T17:59:29.443609Z","iopub.status.idle":"2024-04-25T17:59:34.410175Z","shell.execute_reply.started":"2024-04-25T17:59:29.443579Z","shell.execute_reply":"2024-04-25T17:59:34.408942Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"seq_length = 256\npreprocessed_df[\"tokens\"] = preprocessed_df[\"tokens\"].apply(lambda x: pad_sequence(x, seq_length))\n\ndisplay(preprocessed_df.head())\n# lens = [len(tokens) for tokens in preprocessed_df[\"tokens_padded\"]]\n# print(lens[:200])","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:59:36.278891Z","iopub.execute_input":"2024-04-25T17:59:36.279326Z","iopub.status.idle":"2024-04-25T17:59:36.805341Z","shell.execute_reply.started":"2024-04-25T17:59:36.279293Z","shell.execute_reply":"2024-04-25T17:59:36.803921Z"},"trusted":true},"execution_count":28,"outputs":[{"output_type":"display_data","data":{"text/plain":"                                              review  sentiment  \\\n0  One reviewer ha mentioned watching Oz episode ...          1   \n1  A wonderful little production The filming tech...          1   \n2  I thought wa wonderful way spend time hot summ...          1   \n3  Basically family little boy Jake think zombie ...          0   \n4  Petter Matteis Love Time Money visually stunni...          1   \n\n                                              tokens  \\\n0  [227, 1054, 8, 943, 81, 3772, 184, 439, 2971, ...   \n1  [60, 318, 55, 246, 5, 1242, 1613, 17848, 89094...   \n2  [1, 101, 3, 318, 27, 1009, 9, 896, 1753, 2510,...   \n3  [2724, 141, 55, 249, 3460, 34, 677, 4406, 593,...   \n4  [89098, 35004, 1123, 1977, 7469, 2188, 1279, 4...   \n\n                                       tokens_padded  \n0  [227, 1054, 8, 943, 81, 3772, 184, 439, 2971, ...  \n1  [60, 318, 55, 246, 5, 1242, 1613, 17848, 89094...  \n2  [1, 101, 3, 318, 27, 1009, 9, 896, 1753, 2510,...  \n3  [2724, 141, 55, 249, 3460, 34, 677, 4406, 593,...  \n4  [89098, 35004, 1123, 1977, 7469, 2188, 1279, 4...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n      <th>tokens</th>\n      <th>tokens_padded</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>One reviewer ha mentioned watching Oz episode ...</td>\n      <td>1</td>\n      <td>[227, 1054, 8, 943, 81, 3772, 184, 439, 2971, ...</td>\n      <td>[227, 1054, 8, 943, 81, 3772, 184, 439, 2971, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A wonderful little production The filming tech...</td>\n      <td>1</td>\n      <td>[60, 318, 55, 246, 5, 1242, 1613, 17848, 89094...</td>\n      <td>[60, 318, 55, 246, 5, 1242, 1613, 17848, 89094...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I thought wa wonderful way spend time hot summ...</td>\n      <td>1</td>\n      <td>[1, 101, 3, 318, 27, 1009, 9, 896, 1753, 2510,...</td>\n      <td>[1, 101, 3, 318, 27, 1009, 9, 896, 1753, 2510,...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Basically family little boy Jake think zombie ...</td>\n      <td>0</td>\n      <td>[2724, 141, 55, 249, 3460, 34, 677, 4406, 593,...</td>\n      <td>[2724, 141, 55, 249, 3460, 34, 677, 4406, 593,...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Petter Matteis Love Time Money visually stunni...</td>\n      <td>1</td>\n      <td>[89098, 35004, 1123, 1977, 7469, 2188, 1279, 4...</td>\n      <td>[89098, 35004, 1123, 1977, 7469, 2188, 1279, 4...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"y = np.array(preprocessed_df[\"sentiment\"].tolist())\nX = np.array(preprocessed_df[\"tokens\"].tolist())\n\ntrain_frac, val_frac, test_frac = 0.7, 0.1, 0.2\ntrain_size = int(train_frac*len(X))\nval_size = int(val_frac*len(X))\n\nX_train, y_train = X[:train_size], y[:train_size]\nX_val, y_val = X[train_size:train_size+val_size], y[train_size:train_size+val_size]\nX_test, y_test = X[train_size+val_size:], y[train_size+val_size:]\n\nprint(\"train split: \", X_train.shape, y_train.shape)\nprint(\"val split: \", X_val.shape, y_val.shape)\nprint(\"test split: \", X_test.shape, y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:55:48.435613Z","iopub.execute_input":"2024-04-25T17:55:48.436094Z","iopub.status.idle":"2024-04-25T17:55:49.903382Z","shell.execute_reply.started":"2024-04-25T17:55:48.436057Z","shell.execute_reply":"2024-04-25T17:55:49.901605Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"train:  (35000, 256) (35000,)\nval:  (5000, 256) (5000,)\ntest:  (10000, 256) (10000,)\n","output_type":"stream"}]}]}